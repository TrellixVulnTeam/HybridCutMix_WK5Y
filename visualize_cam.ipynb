{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from utils.gradcam import *\n",
    "from utils.misc import Wrapper, generate_attentive_mask\n",
    "from utils.dataset import CUB200_loaders\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = './results/default/best_model.pth'\n",
    "output_path = './outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered forward/backward hook on 'module.conv1'\n",
      "Registered forward/backward hook on 'module.layer1'\n",
      "Registered forward/backward hook on 'module.layer2'\n",
      "Registered forward/backward hook on 'module.layer3'\n",
      "Registered forward/backward hook on 'module.layer4'\n",
      "Using model with validation accuracy 84.47%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "targets = [\n",
    "    \"conv1\",\n",
    "    \"layer1\",\n",
    "    \"layer2\",\n",
    "    \"layer3\",\n",
    "    \"layer4\"\n",
    "]\n",
    "\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 200)\n",
    "model = nn.DataParallel(model)\n",
    "model = Wrapper(model, targets)\n",
    "state_dict = torch.load(weight_path)\n",
    "model.load_state_dict(state_dict['model'])\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Using model with validation accuracy {state_dict['best_valid_acc']*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!self.root/media/data/\n",
      "!!!self.root/media/data/\n"
     ]
    }
   ],
   "source": [
    "dataset_root = '/media/data/'\n",
    "crop_size = 448\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "train_loader, valid_loader, num_classes = CUB200_loaders(dataset_root, crop_size, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 448, 448])\n",
      "Label: 59\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = next(iter(train_loader))\n",
    "\n",
    "label = int(label[0])\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print(\"Label:\",label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 448, 3)\n"
     ]
    }
   ],
   "source": [
    "tr_image = np.asarray(img_tensor[0].permute(1,2,0))\n",
    "print(tr_image.shape)\n",
    "tr_image = cv2.cvtColor(tr_image,cv2.COLOR_BGR2RGB)\n",
    "tr_image = np.uint8(normalize(tr_image)*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Save directory exists\n",
      "Visualization saved to :  ./outputs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot use both regular backward hooks and full backward hooks on a single Module. Please use only one of them.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e8df4f15b68f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# a.save(os.path.join(save_dir,'_input_image'+'.jpg'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/HybridCutMix/utils/gradcam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mregister_backward_hook\u001b[0;34m(self, hook)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \"\"\"\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks on a \"\n\u001b[0m\u001b[1;32m    691\u001b[0m                                \"single Module. Please use only one of them.\")\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot use both regular backward hooks and full backward hooks on a single Module. Please use only one of them."
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "print('='*20)\n",
    "# =========================================================================\n",
    "\n",
    "save_dir = os.path.join(output_path)\n",
    "\n",
    "if(os.path.isdir(save_dir)):\n",
    "    print('Save directory exists')\n",
    "else:\n",
    "    os.mkdir(save_dir)\n",
    "print('Visualization saved to : ',save_dir)\n",
    "\n",
    "# a.save(os.path.join(save_dir,'_input_image'+'.jpg'))\n",
    "gcam = GradCAM(model=model.net.module)\n",
    "probs, idx = gcam.forward(img_tensor.to(device))\n",
    "\n",
    "# if idx[0] == label:\n",
    "cv2.imwrite(f'./outputs/{label}_raw.png', tr_image)\n",
    "print((probs*100).sum())\n",
    "print(idx[0], label)\n",
    "\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(\"|  Probability  |    Class   |\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "for j in range(0,len(targets)):\n",
    "    gcam.backward(idx=label)\n",
    "    output = gcam.generate(target_layer=targets[j])\n",
    "    print(output.shape)\n",
    "    # Filename : {ClassName}_gcam_{NumLayer}\n",
    "    save_gradcam(save_dir+'/{}_gcam_{}.png'.format(label, targets[j]), output, tr_image)\n",
    "print('[{:.5f}] {}'.format(probs[label], label))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}